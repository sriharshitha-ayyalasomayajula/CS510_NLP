{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a79d93",
   "metadata": {},
   "source": [
    "# Assignment 3: Parts-of-Speech Tagging (10 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6289301c",
   "metadata": {},
   "source": [
    "<font size = 3>1. (0.5pt) Search the web for 2 “spoof newspaper headlines”, to find such gems as: British Left Waffles on Falkland Islands, and Juvenile Court to Try Shooting Defendant. Manually tag these headlines to see if knowledge of the part-of-speech tags removes the ambiguity. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158dfd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Killer Sentenced to Die for Second Time in 10 years\n",
      "Word       Description    Tag\n",
      "---------  -------------  -----\n",
      "Killer     Noun           NNP\n",
      "Sentenced  Verb           VBD\n",
      "to         Preposition    TO\n",
      "Die        Verb           VB\n",
      "for        Conjucntion    IN\n",
      "Second     Adjective      JJ\n",
      "Time       noun           NNP\n",
      "in         Prep           IN\n",
      "10         Number         CD\n",
      "Years      Noun           NNS\n",
      "\n",
      "2. Astronaut Takes Blame For Gas in Spacecraft.\n",
      "Word        Description    Tag\n",
      "----------  -------------  -----\n",
      "Astronaut   Noun           NNP\n",
      "Takes       Verb           VBZ\n",
      "Blame       Noun           NNP\n",
      "for         Conjunction    IN\n",
      "Gas         Noun           NNP\n",
      "in          Preposition    IN\n",
      "Spacecraft  Noun           NNP\n",
      ".           Punctuation    .\n"
     ]
    }
   ],
   "source": [
    "# Answer 1: Manual Tagging\n",
    "from tabulate import tabulate\n",
    "text1 = \"Killer Sentenced to Die for Second Time in 10 years\"\n",
    "\n",
    "man_tag_text1 =[('Killer','Noun','NNP'),('Sentenced','Verb','VBD'),('to','Preposition','TO'),\n",
    "                ('Die','Verb','VB'),('for','Conjucntion','IN'),\n",
    "                ('Second','Adjective','JJ'),('Time','noun','NNP'),\n",
    "                ('in','Prep','IN'),('10','Number','CD'),('Years','Noun','NNS')]\n",
    "\n",
    "print(\"1.\",text1)\n",
    "print(tabulate(man_tag_text1, headers = ['Word','Description','Tag']))\n",
    "print()\n",
    "\n",
    "text2 = \"Astronaut Takes Blame For Gas in Spacecraft.\"\n",
    "\n",
    "man_tag_text2 =[('Astronaut','Noun','NNP'),('Takes','Verb','VBZ'),('Blame','Noun','NNP'),\n",
    "                ('for','Conjunction','IN'),('Gas','Noun','NNP'),\n",
    "                ('in','Preposition','IN'),('Spacecraft','Noun','NNP'),('.','Punctuation','.')]\n",
    "\n",
    "print(\"2.\",text2)\n",
    "print(tabulate(man_tag_text2, headers = ['Word','Description','Tag']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37447554",
   "metadata": {},
   "source": [
    "<font size = 3>2. (0.5pt) Tokenize and tag the following sentence: They wind back the clock, while we chase after the wind. What is the output?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f29d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRP'),\n",
       " ('wind', 'VBP'),\n",
       " ('back', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('clock', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('chase', 'VBP'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('wind', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "text3 =\"They wind back the clock, while we chase after the wind.\"\n",
    "nltk.pos_tag(word_tokenize(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37af01a",
   "metadata": {},
   "source": [
    "<font size = 3>3. (0.5pt) Pick 2 words that can be either a noun or a verb (e.g., contest). Predict which POS tag is likely to be the most frequent in the Brown corpus, and compare with your predictions.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906b3c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRP'),\n",
       " ('began', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('laugh', 'VB'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('realized', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('loudest', 'JJS'),\n",
       " ('laugh', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('’', 'VBP'),\n",
       " ('d', 'JJ'),\n",
       " ('ever', 'RB'),\n",
       " ('heard', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "#nltk.download('brown')\n",
    "text4 = \"She began to laugh, and I realized that it was the loudest laugh I’d ever heard.\"\n",
    "nltk.pos_tag(word_tokenize(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de0e22",
   "metadata": {},
   "source": [
    "<font size = 3> In here, the first laugh is a verb as we are describing the action of a person, and the second laugh is a noun-singular. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e7a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent Tag in Brown Corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('NOUN', 275558),\n",
       " ('VERB', 182750),\n",
       " ('.', 147565),\n",
       " ('ADP', 144766),\n",
       " ('DET', 137019),\n",
       " ('ADJ', 83721),\n",
       " ('ADV', 56239),\n",
       " ('PRON', 49334),\n",
       " ('CONJ', 38151),\n",
       " ('PRT', 29829),\n",
       " ('NUM', 14874),\n",
       " ('X', 1386)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('universal_tagset')\n",
    "bc = nltk.corpus.brown.tagged_words(tagset='universal')\n",
    "tag_fq = nltk.FreqDist(tag for (word, tag) in bc) #for tag frequency\n",
    "print(\"Most frequent Tag in Brown Corpus\")\n",
    "tag_fq.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a555c",
   "metadata": {},
   "source": [
    "<font size = 3>4. (1pt) Use sorted() and set() to get a sorted list of tags used in the Brown corpus, removing duplicates.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "241d826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', '.'), ('$.027', 'NOUN'), ('$.03', 'NOUN'), ('$.054/mbf', 'NOUN'), ('$.07', 'NOUN'), ('$.07/cwt', 'NOUN'), ('$.076', 'NOUN'), ('$.09', 'NOUN'), ('$.10-a-minute', 'NOUN'), ('$.105', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "# Answer 4:\n",
    "print(sorted(set(bc))[:10]) #prints the first 10 tags in the sorted list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892625e",
   "metadata": {},
   "source": [
    "<font size=3> In here, we are just printing the first 10 tags in the sorted list. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1894d23e",
   "metadata": {},
   "source": [
    "<font size = 3>5. (2pt) Write programs to process the Brown Corpus and find answers to the following questions: (i) Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the -s suffix.) (ii) List the top 20 tags in order of decreasing frequency - what do these most frequent tags represent?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af7b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cc84d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Nouns are more common as plural?\n",
      "\n",
      "brothers\n",
      "selves\n",
      "powers\n",
      "ends\n",
      "conversations\n",
      "words\n",
      "languages\n",
      "actions\n",
      "people\n",
      "floods\n",
      "conditions\n",
      "parents\n",
      "changes\n",
      "lights\n",
      "ripples\n",
      "stars\n",
      "plants\n",
      "nymphs\n",
      "nests\n",
      "humans\n",
      "others\n",
      "arms\n",
      "domes\n",
      "sands\n",
      "generations\n",
      "meditations\n",
      "millennia\n",
      "elections\n",
      "marks\n",
      "spaces\n",
      "organs\n",
      "flowers\n",
      "serviettes\n",
      "sexes\n",
      "diapers\n",
      "purses\n",
      "bishops\n",
      "lots\n",
      "denunciations\n",
      "recriminations\n",
      "warts\n",
      "workers\n",
      "gripes\n",
      "wings\n",
      "clinches\n",
      "girls\n",
      "patterns\n",
      "ways\n",
      "women\n",
      "pieces\n",
      "secretaries\n",
      "tears\n",
      "personae\n",
      "events\n",
      "eyes\n",
      "drives\n",
      "years\n",
      "beings\n",
      "lessons\n",
      "impressions\n",
      "scars\n",
      "thoughts\n",
      "records\n",
      "orders\n",
      "lightyears\n",
      "men\n",
      "specialists\n",
      "linguists\n",
      "professionals\n",
      "pardons\n",
      "hands\n",
      "enemies\n",
      "months\n",
      "megalopolises\n",
      "discs\n",
      "necklaces\n",
      "terms\n",
      "members\n",
      "states\n",
      "peoples\n",
      "purposes\n",
      "borders\n",
      "citizens\n",
      "tongues\n",
      "descendants\n",
      "days\n",
      "friends\n",
      "associates\n",
      "passengers\n",
      "frauds\n",
      "personnel\n",
      "ashes\n",
      "winds\n",
      "bodies\n",
      "barriers\n",
      "preparations\n",
      "recordings\n",
      "cases\n",
      "means\n",
      "students\n",
      "natives\n",
      "sounds\n",
      "approximations\n",
      "tenses\n",
      "genders\n",
      "parts\n",
      "nouns\n",
      "pronouns\n",
      "adjectives\n",
      "adverbs\n",
      "conjunctions\n",
      "verbs\n",
      "assumptions\n",
      "value-judgments\n",
      "motives\n",
      "millions\n",
      "answers\n",
      "questions\n",
      "dice\n",
      "races\n",
      "periods\n",
      "individuals\n",
      "nations\n",
      "commodities\n",
      "quarters\n",
      "reactors\n",
      "customs\n",
      "dictates\n",
      "natures\n",
      "judgments\n",
      "laws\n",
      "restraints\n",
      "preferences\n",
      "violations\n",
      "absolutes\n",
      "outsiders\n",
      "agreements\n",
      "intentions\n",
      "supplies\n",
      "details\n",
      "beginnings\n",
      "matters\n",
      "screens\n",
      "lips\n",
      "elders\n",
      "directions\n",
      "instruments\n",
      "skies\n",
      "boards\n",
      "streaks\n",
      "spacesuits\n",
      "holes\n",
      "plots\n",
      "facts\n",
      "feet\n",
      "fuses\n",
      "minutes\n",
      "guys\n",
      "bluffs\n",
      "planets\n",
      "scientists\n",
      "planetoids\n",
      "neighbors\n",
      "helmets\n",
      "gases\n",
      "Animals\n",
      "readings\n",
      "needles\n",
      "works\n",
      "dials\n",
      "results\n",
      "bacteria\n",
      "insects\n",
      "types\n",
      "defenses\n",
      "categories\n",
      "chills\n",
      "contrasts\n",
      "matches\n",
      "beasts\n",
      "creatures\n",
      "deposits\n",
      "critters\n",
      "aliens\n",
      "bubbles\n",
      "Insects\n",
      "couches\n",
      "doctors\n",
      "Others\n",
      "processes\n",
      "poisons\n",
      "shipmates\n",
      "grounds\n",
      "buddies\n",
      "watches\n",
      "reports\n",
      "dreams\n",
      "lines\n",
      "repercussions\n",
      "constellations\n",
      "mates\n",
      "seconds\n",
      "games\n",
      "beasties\n",
      "animals\n",
      "corpses\n",
      "things\n",
      "tapes\n",
      "explanations\n",
      "pounds\n",
      "claws\n",
      "children\n",
      "babies\n",
      "shells\n",
      "responses\n",
      "wheels\n",
      "extensions\n",
      "synapses\n",
      "mechanisms\n",
      "tests\n",
      "expectations\n",
      "side-effects\n",
      "doses\n",
      "pressures\n",
      "resources\n",
      "ships\n",
      "stages\n",
      "babes\n",
      "techniques\n",
      "transfers\n",
      "panels\n",
      "dwarfs\n",
      "deformities\n",
      "places\n",
      "classmates\n",
      "codes\n",
      "teachers\n",
      "precepts\n",
      "associations\n",
      "inhumanities\n",
      "shoulders\n",
      "histories\n",
      "photographs\n",
      "committees\n",
      "photos\n",
      "objections\n",
      "tools\n",
      "repairs\n",
      "cords\n",
      "diaphragms\n",
      "microphones\n",
      "mouths\n",
      "wanderings\n",
      "visitors\n",
      "craters\n",
      "pores\n",
      "proportions\n",
      "peculiarities\n",
      "distances\n",
      "discussions\n",
      "values\n",
      "ladies\n",
      "gentlemen\n",
      "angels\n",
      "singers\n",
      "progressions\n",
      "chromatics\n",
      "concerti\n",
      "difficulties\n",
      "situations\n",
      "restrictions\n",
      "limitations\n",
      "methods\n",
      "centuries\n",
      "lungs\n",
      "muscles\n",
      "sinuses\n",
      "authorities\n",
      "connections\n",
      "extendibles\n",
      "taps\n",
      "proceedings\n",
      "annals\n",
      "minds\n",
      "flights\n",
      "adventures\n",
      "scouts\n",
      "missions\n",
      "heads\n",
      "partners\n",
      "scanners\n",
      "directives\n",
      "technicians\n",
      "fingernails\n",
      "clothes\n",
      "times\n",
      "People\n",
      "knives\n",
      "ministrations\n",
      "dromozoa\n",
      "screams\n",
      "agonies\n",
      "nerves\n",
      "phenomena\n",
      "needs\n",
      "cycles\n",
      "pains\n",
      "torsos\n",
      "arteries\n",
      "cards\n",
      "figures\n",
      "plays\n",
      "dummies\n",
      "hummocks\n",
      "lovelies\n",
      "clocks\n",
      "calendars\n",
      "Earth-weeks\n",
      "eyebrows\n",
      "legs\n",
      "toe-tips\n",
      "teratologies\n",
      "thousands\n",
      "smiles\n",
      "victims\n",
      "ones\n",
      "brains\n",
      "herds\n",
      "hours\n",
      "hopes\n",
      "cow-people\n",
      "eggs\n",
      "miles\n",
      "geysers\n",
      "crops\n",
      "shocks\n",
      "courses\n",
      "names\n",
      "rockets\n",
      "plans\n",
      "fingers\n"
     ]
    }
   ],
   "source": [
    "print (\"Which Nouns are more common as plural?\\n\")\n",
    "sft = nltk.corpus.brown.tagged_words(categories ='science_fiction')\n",
    "#Here we are using Condition Frequency Distance - word, tag frequencies\n",
    "cfd = nltk.ConditionalFreqDist(sft)\n",
    "cd = cfd.conditions()\n",
    "num_tags = []\n",
    "for condition in cd:\n",
    "    if cfd[condition]['NNS'] > cfd[condition]['NN']:\n",
    "        print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf1b4e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 tags in decreasing frequency:\n",
      "[('NN', 1541), ('IN', 1176), ('.', 1077), ('AT', 1040), (',', 791), ('JJ', 723), ('NNS', 532), ('VBD', 531), ('RB', 522), ('VB', 495), ('CC', 415), ('NP', 387), ('PPS', 336), ('VBN', 318), ('PPSS', 282), ('PP$', 272), ('CS', 269), ('PPO', 252), ('``', 235), (\"''\", 235)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 20 tags in decreasing frequency:\")\n",
    "tagfd = nltk.FreqDist(tag for (word,tag)  in  sft)\n",
    "print (tagfd.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56abd1c1",
   "metadata": {},
   "source": [
    "<font size = 3>6. (2.5pt) Generate some statistics for tagged data to answer the following questions: \n",
    "(i) What proportion of word types are always assigned the same part-of-speech tag? \n",
    "(ii) How many word types are ambiguous, in the sense that they appear with at least two tags? (iii) What percentage of word tokens in the Brown Corpus involve these ambiguous word types?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1cd0e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What propostion of word types are always assigned the same POS for science_fiction\n",
      "0.9325703680791835\n",
      "How many word types are ambiguos for science_fiction\n",
      "218\n",
      "What percentage of word token in brown corpus involve the ambiguous word types\n",
      "0.002596469834445983\n"
     ]
    }
   ],
   "source": [
    "unique_tag = [condition for condition in cd if len(cfd[condition]) == 1]\n",
    "print(\"What propostion of word types are always assigned the same POS for science_fiction\")\n",
    "unique_tag_p = len(unique_tag) / len(cd)\n",
    "print(unique_tag_p)\n",
    "\n",
    "print(\"How many word types are ambiguos for science_fiction\")\n",
    "unique_tag_num = len(cd) - len(unique_tag) \n",
    "print(unique_tag_num)\n",
    "\n",
    "print(\"What percentage of word token in brown corpus involve the ambiguous word types\")\n",
    "bw = brown.words()\n",
    "total_number_bw = set(bw)\n",
    "cw_num = [word for word in unique_tag if word in total_number_bw]\n",
    "print(len(cw_num)/len(bw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e74f92",
   "metadata": {},
   "source": [
    "<font size = 3> 7.  Write code to search the Brown Corpus for particular words and phrases according to tags, to answer the following questions: (i) Produce an alphabetically sorted list of the distinct words tagged as MD. (ii) Identify words that can be plural nouns or third person singular verbs (e.g. deals, flies). (iii) What is the ratio of masculine to feminine pronouns?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89bcc015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can', 'Could', 'May', 'Might', 'Must', 'Ought', 'Shall', 'Should', 'Will', 'Would', \"c'n\", 'can', 'colde', 'could', 'dare', 'kin', 'maht', 'mai', 'may', 'maye', 'mayst', 'might', 'must', 'need', 'ought', 'shall', 'should', 'shuld', 'shulde', 'wil', 'will', 'wilt', 'wod', 'wold', 'wolde', 'would']\n"
     ]
    }
   ],
   "source": [
    "#Here we are trying to sort the list of words in brown corpus w.r.t MD(modal auxilary) tag using conditions\n",
    "text5 = nltk.corpus.brown.words()\n",
    "tagged_text = nltk.corpus.brown.tagged_words()\n",
    "set_text = set(text5)\n",
    "new_cfd = nltk.ConditionalFreqDist(tagged_text)\n",
    "new_cd = new_cfd.conditions()\n",
    "\n",
    "md_words = [condition for condition in new_cd if new_cfd[condition]['MD'] != 0] \n",
    "md_words.sort()\n",
    "print(md_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be69b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aids', 'Designs', 'Increases', 'Makes', 'Reports', 'Says', 'accounts', 'acts', 'addresses', 'advances', 'affects', 'aids', 'aims', 'amounts', 'answers', 'appeals', 'approaches', 'arches', 'assaults', 'associates', 'attacks', 'attempts', 'attributes', 'backs', 'bangs', 'banks', 'bargains', 'bars', 'bases', 'bats', 'beats', 'bellows', 'belts', 'bends', 'benefits', 'bites', 'blankets', 'blots', 'blows', 'blueprints', 'boards', 'bodies', 'borders', 'bores', 'bottles', 'bows', 'breaks', 'bridges', 'bristles', 'bubbles', 'bugs', 'bulletins', 'bullies', 'burns', 'butts', 'calls', 'caps', 'captures', 'cares', 'casts', 'catches', 'causes', 'censors', 'centers', 'challenges', 'champions', 'changes', 'charges', 'checks', 'claims', 'claps', 'clicks', 'clouds', 'clucks', 'clutches', 'colors', 'commands', 'comments', 'compounds', 'compresses', 'concentrates', 'concerns', 'conducts', 'conflicts', 'contacts', 'contracts', 'contrasts', 'controls', 'coordinates', 'costs', 'counts', 'courts', 'covers', 'cracks', 'credits', 'cries', 'crops', 'crosses', 'cuts', 'cycles', 'damages', 'dances', 'dashes', 'dates', 'deals', 'declines', 'decreases', 'decrees', 'deeds', 'delays', 'delights', 'demands', 'deserts', 'designs', 'desires', 'dictates', 'dies', 'dishes', 'dislikes', 'displays', 'dogs', 'doubles', 'drains', 'dreams', 'drifts', 'drinks', 'drives', 'drops', 'dwarfs', 'embraces', 'encounters', 'ends', 'equals', 'escapes', 'estimates', 'excuses', 'exercises', 'exhibits', 'experiences', 'extracts', 'faces', 'factors', 'falls', 'fans', 'fashions', 'favors', 'fears', 'features', 'feeds', 'fields', 'fights', 'figures', 'files', 'finishes', 'fishes', 'fits', 'flags', 'flares', 'flies', 'flourishes', 'flows', 'forces', 'forms', 'fractures', 'functions', 'gains', 'gestures', 'glories', 'graduates', 'guarantees', 'guides', 'handles', 'harbors', 'hates', 'hauls', 'haunts', 'heads', 'helps', 'hides', 'hinges', 'hints', 'hits', 'holds', 'honors', 'hopes', 'houses', 'howls', 'hunts', 'imports', 'increases', 'influences', 'initiates', 'interests', 'issues', 'jokes', 'jumps', 'keeps', 'kicks', 'kids', 'kills', 'kisses', 'knocks', 'knuckles', 'labels', 'labors', 'lags', 'lands', 'laps', 'lapses', 'laughs', 'lays', 'leads', 'leaps', 'leases', 'leaves', 'levels', 'lies', 'lifts', 'lights', 'likes', 'limits', 'lines', 'lists', 'lives', 'looks', 'looms', 'loves', 'makes', 'marches', 'markets', 'marks', 'matches', 'matters', 'means', 'measures', 'meets', 'mentions', 'merits', 'mirrors', 'misses', 'mistakes', 'moderates', 'mounts', 'moves', 'names', 'needs', 'notes', 'numbers', 'objects', 'offers', 'orders', 'outlines', 'paints', 'parades', 'parallels', 'passes', 'pauses', 'peers', 'permits', 'petitions', 'phones', 'photographs', 'picks', 'pictures', 'piles', 'places', 'plans', 'plays', 'plots', 'plunges', 'points', 'powers', 'practices', 'presents', 'preserves', 'presses', 'proceeds', 'projects', 'promises', 'protests', 'pulls', 'purchases', 'purges', 'pushes', 'quarrels', 'questions', 'rains', 'raises', 'rallies', 'ranches', 'ranges', 'ranks', 'rates', 'reaches', 'reasons', 'rebels', 'records', 'regards', 'registers', 'regrets', 'releases', 'remains', 'remarks', 'replies', 'reports', 'requests', 'reserves', 'respects', 'rests', 'results', 'returns', 'reviews', 'rides', 'rings', 'rises', 'rocks', 'rolls', 'rules', 'runs', 'rushes', 'sanctions', 'says', 'scales', 'scans', 'seals', 'searches', 'senses', 'services', 'sets', 'shakes', 'shapes', 'shares', 'sheds', 'shifts', 'shocks', 'shouts', 'shows', 'signals', 'signs', 'sketches', 'skins', 'skirts', 'slips', 'smells', 'smiles', 'snatches', 'sneers', 'snowballs', 'snows', 'solos', 'sounds', 'spans', 'sparks', 'speeds', 'spies', 'splashes', 'splits', 'sponsors', 'sports', 'spreads', 'springs', 'stains', 'stakes', 'stands', 'starts', 'states', 'stays', 'stems', 'steps', 'sticks', 'stops', 'stresses', 'stretches', 'strikes', 'struggles', 'studies', 'subjects', 'suits', 'sums', 'supplies', 'supports', 'surveys', 'switches', 'swoops', 'talks', 'tastes', 'terms', 'tests', 'thrusts', 'ties', 'times', 'tires', 'tops', 'tortures', 'totals', 'touches', 'towers', 'toys', 'traces', 'trades', 'trains', 'transfers', 'transports', 'traps', 'travels', 'treats', 'tries', 'trusts', 'turns', 'upsets', 'urges', 'uses', 'values', 'views', 'visits', 'votes', 'vows', 'walks', 'wants', 'watches', 'weights', 'winds', 'wins', 'wishes', 'wonders', 'works', 'worries', 'wrenches', 'yields']\n"
     ]
    }
   ],
   "source": [
    "#Here we are trying to find the words that are NNS or VBZ by using conditions\n",
    "id_words = [condition for condition in new_cd if new_cfd[condition]['NNS'] and new_cfd[condition]['VBZ']]\n",
    "id_words.sort()\n",
    "print(id_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "648d8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3384615384615386\n"
     ]
    }
   ],
   "source": [
    "#consider the tag frequency of words in brown corpus\n",
    "#in here we consider the pronoun tags of both male and female and got the ratio of it . \n",
    "bfd = nltk.FreqDist(text5)\n",
    "mfratio = (bfd['he'] + bfd['He']) / (bfd['she'] + bfd['She']) \n",
    "print(mfratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deec789",
   "metadata": {},
   "source": [
    "<font size = 3>8. (3pt) How serious is the sparse data problem? Investigate the performance of n-gram taggers as n increases from 1 to 6. Tabulate the accuracy score.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c69bf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.800383877159309\n",
      "0.12795905310300704\n",
      "0.08061420345489444\n",
      "0.07869481765834933\n",
      "0.07741522712731926\n"
     ]
    }
   ],
   "source": [
    "bts = nltk.corpus.brown.tagged_sents(categories='science_fiction') \n",
    "size = int(len(bts) * 0.9)\n",
    "train_sents = bts[:size]\n",
    "test_sents = bts[size:]\n",
    "\n",
    "ngram_tag = nltk.NgramTagger(2, train_sents)\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "for i in range(1,6):\n",
    "    ngram_tagger = nltk.NgramTagger(i, train_sents)\n",
    "    print(ngram_tagger.accuracy(test_sents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0b35e",
   "metadata": {},
   "source": [
    "<font size = 3> References:\n",
    "    1. [NLP by Steven Bird](https://www.nltk.org/book/)\n",
    "    2. [FreDist](https://tedboy.github.io/nlps/generated/generated/nltk.FreqDist.html)\n",
    "    3. [ConditionalFreqDist](https://tedboy.github.io/nlps/generated/generated/nltk.ConditionalFreqDist.html)\n",
    "    4. [Ngram](https://tedboy.github.io/nlps/generated/generated/nltk.NgramTagger.html)\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
